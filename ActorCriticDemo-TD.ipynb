{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f588b90-45c6-4d60-851b-ac72fb956404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2009c7de-f2c8-4fdf-8f72-6b224a23f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bf7687-bf57-466f-8a17-9c98587092a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, feature_extractor_network: nn.Module, feature_dims : int, parameter_vector_dims : int):\n",
    "        super().__init__()\n",
    "        self.feature_extractor_network = feature_extractor_network\n",
    "        \n",
    "        self.actor_head = nn.Sequential(\n",
    "            # Note:\n",
    "            # input num dims = 2 * feature_dims + parameter_vector_dims\n",
    "            # because actor head will get a concatenation of the following:\n",
    "            #    - feature vector of target spectrogram\n",
    "            #    - feature vector of prior spectrogram generated from the prior predicted parameter vector\n",
    "            #    - feature vector of prior predicted parameter vector\n",
    "            nn.Linear(2 * feature_dims + parameter_vector_dims, parameter_vector_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(parameter_vector_dims, parameter_vector_dims),\n",
    "\n",
    "            # This final sigmoid activation ensures each param output is in the [0,1] range\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, target_spectrogram, prior_spectrogram, prior_parameter_vector):\n",
    "        # Extract spectrogram features\n",
    "        target_spectrogram_feats = self.feature_extractor_network(target_spectrogram)\n",
    "        prior_spectrogram_feats = self.feature_extractor_network(prior_spectrogram)\n",
    "        state_vec = torch.hstack((target_spectrogram_feats, prior_spectrogram_feats, prior_parameter_vector))\n",
    "        \n",
    "        # Get action from actor network\n",
    "        pi = self.actor_head(state_vec)\n",
    "        \n",
    "        return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85bbd2e-47e5-409a-9835-5166018079f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, feature_extractor_network: nn.Module, feature_dims : int, parameter_vector_dims : int):\n",
    "        super().__init__()\n",
    "        self.feature_extractor_network = feature_extractor_network\n",
    "                \n",
    "        self.critic_head = nn.Sequential(\n",
    "            # See prior note for explanation behind number of input dims here\n",
    "            nn.Linear(2 * feature_dims + parameter_vector_dims, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            \n",
    "            # We use a final tanh for the critic head's output value, to squash it between 1 and -1\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, target_spectrogram, prior_spectrogram, prior_parameter_vector):\n",
    "        # Extract spectrogram features\n",
    "        target_spectrogram_feats = self.feature_extractor_network(target_spectrogram)\n",
    "        prior_spectrogram_feats = self.feature_extractor_network(prior_spectrogram)\n",
    "        state_vec = torch.hstack((target_spectrogram_feats, prior_spectrogram_feats, prior_parameter_vector))\n",
    "        \n",
    "        # Get predicted Q(s,a) value from critic network\n",
    "        value = self.critic_head(state_vec)\n",
    "        \n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee626dbb-e519-46b7-8957-c3dbcccc878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_shape = (1, 128, 512)\n",
    "parameter_vector_dims = 256\n",
    "feature_vector_dims=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59156b1b-9e77-4573-ac42-119c8c8aa34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 65536])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [parameter vector dims, spectrogram flattened num dims]\n",
    "parameter_vector_to_spectrogram_matrix = torch.randn(parameter_vector_dims, np.prod(spectrogram_shape), requires_grad=False, device=device)\n",
    "parameter_vector_to_spectrogram_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c34c503-69b9-42a8-b65f-5f628af26593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram_from_parameter_vector(parameter_vector):\n",
    "    # [N, spectrogram flattened num dims]\n",
    "    spectrogram_flattened = parameter_vector @ parameter_vector_to_spectrogram_matrix\n",
    "    spectrogram = torch.reshape(spectrogram_flattened, (-1,) + spectrogram_shape)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202764d7-713a-4834-9f49-b87027f0b5f8",
   "metadata": {},
   "source": [
    "## Demo training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcf889a-4a89-4788-b56e-e0822ee371cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fcd853-58b8-43f9-ac1b-b82af38376fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 1, 128, 512]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_params_vector = torch.randn(1, parameter_vector_dims, device=device)\n",
    "ground_truth_spectrogram = generate_spectrogram_from_parameter_vector(ground_truth_params_vector)\n",
    "ground_truth_params_vector.shape, ground_truth_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14274a0b-1a10-4029-bb6c-d1300d2d4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_between_spectrograms(spec1, spec2):\n",
    "    # output: [N,1]\n",
    "    return ((spec1 - spec2)**2).mean([1,2,3]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a75acb-639d-4d80-b4bc-6244a82fcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(spec1, spec2):\n",
    "    # output: [N,1]\n",
    "    \n",
    "    # first, we compute mse loss and use that to construct a reward\n",
    "    mse_loss = compute_mse_between_spectrograms(spec1, spec2)\n",
    "    \n",
    "    # with the transformation below, higher mse loss -> lower reward, and lower mse loss -> higher reward\n",
    "    reward = -mse_loss #1/mse_loss #-torch.log(mse_loss) #1/mse_loss\n",
    "    \n",
    "    # finally, to keep reward within [-1,1] range, we use tanh\n",
    "    # reward = torch.tanh(reward)\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662c1bbb-1917-49fa-946b-5136ec74ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(rewards, gamma=0.99):\n",
    "    \"\"\"\n",
    "    https://github.com/yc930401/Actor-Critic-pytorch/blob/5d359bc93839357255b591c0a87fc42542854eb8/Actor-Critic.py#L50\n",
    "    \"\"\"\n",
    "    returns = []\n",
    "    \n",
    "    R = rewards[-1]\n",
    "\n",
    "    for idx, step in enumerate(reversed(range(len(rewards)))):\n",
    "        if idx == 0:\n",
    "            R = rewards[step]\n",
    "        else:\n",
    "            R = rewards[step] + gamma * R\n",
    "        returns.insert(0, R)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3830e93b-237a-4f66-a79b-c2f1d24de2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummySpectrogramFeatureExtractorNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a dummy placeholder spectrogram feature extractor, that will convert any input spectrogram into a output feature vector.\n",
    "    The pre-trained VAE, for example, would ideally replace this.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, spectrogram_shape : tuple[int], feature_dims : int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(np.prod(spectrogram_shape), feature_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dims, feature_dims)\n",
    "        )\n",
    "    \n",
    "    def forward(self, spectrogram):\n",
    "        # flatten spectrogram into [N, flattened dims]\n",
    "        spectrogram_flattened = torch.flatten(spectrogram, start_dim=1)\n",
    "        return self.model(spectrogram_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875976b5-d21a-4dad-9773-ffd37dd72207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(predicted_parameter_vector):\n",
    "    next_spectrogram = generate_spectrogram_from_parameter_vector(predicted_parameter_vector)\n",
    "    return [ground_truth_spectrogram, next_spectrogram, predicted_parameter_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc6e852-291b-4ee1-a9e5-5d5935ded341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR_LR = 1e-9\n",
    "CRITIC_LR = 1e-8\n",
    "\n",
    "num_episodes = 1_000_000\n",
    "num_steps_per_episode = 1_000\n",
    "gamma = 0.99\n",
    "\n",
    "GRADIENT_CLIPPING = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db1354d8-41a1-4f35-b676-889a534539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_network = DummySpectrogramFeatureExtractorNetwork(spectrogram_shape=spectrogram_shape, feature_dims=feature_vector_dims)\n",
    "_ = feature_extractor_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1687b14-888f-4b5b-b6df-35905466ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model = ActorNetwork(feature_extractor_network=feature_extractor_network, feature_dims=feature_vector_dims, parameter_vector_dims=parameter_vector_dims).to(device)\n",
    "critic_model = CriticNetwork(feature_extractor_network=feature_extractor_network, feature_dims=feature_vector_dims, parameter_vector_dims=parameter_vector_dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13eaaec-7345-4ea5-b434-ba6c1b38ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optimizer = Adam(actor_model.parameters(), lr=ACTOR_LR)\n",
    "critic_optimizer = Adam(critic_model.parameters(), lr=CRITIC_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6291f-2132-417d-8ba4-af5790b89323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b2e08d00e043ad857267e7b7d62b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bebfe0ef764449b4c2dbabfeaa481f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbb840346a849bfaeb0033b04e93c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9750c221e28499b91330634a46ed8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2612f3785e4737b7f80a3a5b26e66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f417449ae77c40c99bb6f90d586f2650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c3995aecbe4138831fc2a8348f602e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a0c81cd73c4ff6a89d4fc196757312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafa1ad402514de5bd8e82752115ad63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469c416155174443a1ededd971c6d2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1497e62c1902479dbaf7bf00dc376db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba7813c35a443d0b2a1de0aeea3faf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ace17049424392a7e105946c94d67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea87a0155dc4c5484b8d95966129195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4653a4cc80c24bb3994f438c56d3ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d6653df66e4323b82469e11abf19be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791ac9d0ffdc41beafa1bd8f99c31bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b968be5d684b70be9f15b00ab20976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31079bc0e57e4c04842d2bb7ae5028a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab411b165d334518b23846874588d1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_pbar = tqdm(range(num_episodes))\n",
    "for episode_idx in episode_pbar: #range(num_episodes):\n",
    "    # Set initial state for episode\n",
    "    prior_predicted_parameter_vector = torch.zeros((1,parameter_vector_dims), device=device)\n",
    "    prior_predicted_spectrogram = generate_spectrogram_from_parameter_vector(prior_predicted_parameter_vector)\n",
    "    \n",
    "    state = (ground_truth_spectrogram, prior_predicted_spectrogram, prior_predicted_parameter_vector)\n",
    "    \n",
    "    all_rewards = []\n",
    "    \n",
    "    episode_step_pbar = tqdm(range(num_steps_per_episode))\n",
    "    for step_idx in episode_step_pbar:\n",
    "        actor_optimizer.zero_grad()\n",
    "        critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Get predicted action and value for current state\n",
    "        predicted_parameter_vector, value_of_current_state = actor_model(*state), critic_model(*state)\n",
    "        \n",
    "        # Perform action to get next state and reward\n",
    "        next_state = get_next_state(predicted_parameter_vector)\n",
    "        reward = compute_reward(ground_truth_spectrogram, next_state[1])\n",
    "        \n",
    "        value_next_state = critic_model(*next_state)\n",
    "        \n",
    "        #TD Target: r + gamma * V(next_state)\n",
    "        td_target = reward + gamma * value_next_state\n",
    "        \n",
    "        delta = td_target - value_of_current_state\n",
    "        \n",
    "        actor_loss = delta * -torch.log(predicted_parameter_vector).mean(-1)\n",
    "        critic_loss = delta ** 2\n",
    "        \n",
    "        # We're weighting critic loss by 0.5\n",
    "        loss = actor_loss + 0.5*critic_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if GRADIENT_CLIPPING is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(actor_model.parameters(), GRADIENT_CLIPPING)\n",
    "            torch.nn.utils.clip_grad_norm_(critic_model.parameters(), GRADIENT_CLIPPING)\n",
    "        \n",
    "        actor_optimizer.step()\n",
    "        critic_optimizer.step()\n",
    "        \n",
    "        # Now that we've learned from this step, update current state variable\n",
    "        next_state[1] = next_state[1].detach()\n",
    "        next_state[2] = next_state[2].detach()\n",
    "        state = next_state\n",
    "        \n",
    "        all_rewards.append(reward.item())\n",
    "        \n",
    "        episode_step_pbar.set_postfix({\"loss\" : loss.item(), \"reward\" : reward.item()})\n",
    "        \n",
    "    # print (f\"Episode {episode_idx + 1}: total reward: {sum(all_rewards)}, return: {compute_returns(all_rewards, gamma)[0]}\")\n",
    "    episode_pbar.set_postfix({\"total reward\" : sum(all_rewards), \"return\" : compute_returns(all_rewards, gamma)[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
